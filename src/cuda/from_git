template <typename T, bool ASCENDING>
__global__ void BitonicSortGlobalKernel(T* values, const int num_total_data) {
  const int thread_index = static_cast<int>(threadIdx.x);
  const int low = static_cast<int>(blockIdx.x * BITONIC_SORT_NUM_ELEMENTS);
  const bool outer_ascending = ASCENDING ? (blockIdx.x % 2 == 0) : (blockIdx.x % 2 == 1);
  T* values_pointer = values + low;
  const int num_data = min(BITONIC_SORT_NUM_ELEMENTS, num_total_data - low);
  __shared__ T shared_values[BITONIC_SORT_NUM_ELEMENTS];
  if (thread_index < num_data) {
    shared_values[thread_index] = values_pointer[thread_index];
  }
  __syncthreads();
  for (int depth = BITONIC_SORT_DEPTH - 1; depth >= 1; --depth) {
    const int segment_length = 1 << (BITONIC_SORT_DEPTH - depth);
    const int segment_index = thread_index / segment_length;
    const bool ascending = outer_ascending ? (segment_index % 2 == 0) : (segment_index % 2 == 1);
    const int num_total_segment = (num_data + segment_length - 1) / segment_length;
    {
      const int inner_depth = depth;
      const int inner_segment_length_half = 1 << (BITONIC_SORT_DEPTH - 1 - inner_depth);
      const int inner_segment_index_half = thread_index / inner_segment_length_half;
      const int offset = ((inner_segment_index_half >> 1) == num_total_segment - 1 && ascending == ASCENDING) ?
        (num_total_segment * segment_length - num_data) : 0;
      const int segment_start = segment_index * segment_length;
      if (inner_segment_index_half % 2 == 0) {
        if (thread_index >= offset + segment_start) {
          const int index_to_compare = thread_index + inner_segment_length_half - offset;
          if (index_to_compare < num_data && (shared_values[thread_index] > shared_values[index_to_compare]) == ascending) {
            const T tmp = shared_values[thread_index];
            shared_values[thread_index] = shared_values[index_to_compare];
            shared_values[index_to_compare] = tmp;
          }
        }
      }
      __syncthreads();
    }
    for (int inner_depth = depth + 1; inner_depth < BITONIC_SORT_DEPTH; ++inner_depth) {
      const int inner_segment_length_half = 1 << (BITONIC_SORT_DEPTH - 1 - inner_depth);
      const int inner_segment_index_half = thread_index / inner_segment_length_half;
      if (inner_segment_index_half % 2 == 0) {
        const int index_to_compare = thread_index + inner_segment_length_half;
        if (index_to_compare < num_data && (shared_values[thread_index] > shared_values[index_to_compare]) == ascending) {
          const T tmp = shared_values[thread_index];
          shared_values[thread_index] = shared_values[index_to_compare];
          shared_values[index_to_compare] = tmp;
        }
      }
      __syncthreads();
    }
  }
  if (thread_index < num_data) {
    values_pointer[thread_index] = shared_values[thread_index];
  }
}

template <typename VAL_T, bool ASCENDING>
__global__ void BitonicSortMergeKernel(VAL_T* values, const int segment_length, const int len) {
  const int thread_index = static_cast<int>(threadIdx.x + blockIdx.x * blockDim.x);
  const int segment_index = thread_index / segment_length;
  const bool ascending = ASCENDING ? (segment_index % 2 == 0) : (segment_index % 2 == 1);
  __shared__ VAL_T shared_values[BITONIC_SORT_NUM_ELEMENTS];
  const int offset = static_cast<int>(blockIdx.x * blockDim.x);
  const int local_len = min(BITONIC_SORT_NUM_ELEMENTS, len - offset);
  if (thread_index < len) {
    shared_values[threadIdx.x] = values[thread_index];
  }
  __syncthreads();
  int half_segment_length = BITONIC_SORT_NUM_ELEMENTS / 2;
  while (half_segment_length >= 1) {
    const int half_segment_index = static_cast<int>(threadIdx.x) / half_segment_length;
    if (half_segment_index % 2 == 0) {
      const int index_to_compare = static_cast<int>(threadIdx.x) + half_segment_length;
      if (index_to_compare < local_len && ((shared_values[threadIdx.x] > shared_values[index_to_compare]) == ascending)) {
        const VAL_T tmp = shared_values[index_to_compare];
        shared_values[index_to_compare] = shared_values[threadIdx.x];
        shared_values[threadIdx.x] = tmp;
      }
    }
    __syncthreads();
    half_segment_length >>= 1;
  }
  if (thread_index < len) {
    values[thread_index] = shared_values[threadIdx.x];
  }
}

template <typename VAL_T, bool ASCENDING, bool BEGIN>
__global__ void BitonicCompareKernel(VAL_T* values, const int half_segment_length, const int outer_segment_length, const int len) {
  const int thread_index = static_cast<int>(threadIdx.x + blockIdx.x * blockDim.x);
  const int segment_index = thread_index / outer_segment_length;
  const int half_segment_index = thread_index / half_segment_length;
  const bool ascending = ASCENDING ? (segment_index % 2 == 0) : (segment_index % 2 == 1);
  if (half_segment_index % 2 == 0) {
    const int num_total_segment = (len + outer_segment_length - 1) / outer_segment_length;
    if (BEGIN && (half_segment_index >> 1) == num_total_segment - 1 && ascending == ASCENDING) {
      const int offset = num_total_segment * outer_segment_length - len;
      const int segment_start = segment_index * outer_segment_length;
      if (thread_index >= offset + segment_start) {
        const int index_to_compare = thread_index + half_segment_length - offset;
        if (index_to_compare < len && (values[thread_index] > values[index_to_compare]) == ascending) {
          const VAL_T tmp = values[index_to_compare];
          values[index_to_compare] = values[thread_index];
          values[thread_index] = tmp;
        }
      }
    } else {
      const int index_to_compare = thread_index + half_segment_length;
      if (index_to_compare < len) {
        if ((values[thread_index] > values[index_to_compare]) == ascending) {
          const VAL_T tmp = values[index_to_compare];
          values[index_to_compare] = values[thread_index];
          values[thread_index] = tmp;
        }
      }
    }
  }
}

template <typename VAL_T, bool ASCENDING>
void BitonicSortGlobalHelper(VAL_T* values, const size_t len) {
  int max_depth = 1;
  int len_to_shift = static_cast<int>(len) - 1;
  while (len_to_shift > 0) {
    ++max_depth;
    len_to_shift >>= 1;
  }
  const int num_blocks = (static_cast<int>(len) + BITONIC_SORT_NUM_ELEMENTS - 1) / BITONIC_SORT_NUM_ELEMENTS;
  BitonicSortGlobalKernel<VAL_T, ASCENDING><<<num_blocks, BITONIC_SORT_NUM_ELEMENTS>>>(values, static_cast<int>(len));
  SynchronizeCUDADeviceOuter(__FILE__, __LINE__);
  for (int depth = max_depth - 11; depth >= 1; --depth) {
    const int segment_length = (1 << (max_depth - depth));
    int half_segment_length = (segment_length >> 1);
    {
      BitonicCompareKernel<VAL_T, ASCENDING, true><<<num_blocks, BITONIC_SORT_NUM_ELEMENTS>>>(values, half_segment_length, segment_length, static_cast<int>(len));
      SynchronizeCUDADeviceOuter(__FILE__, __LINE__);
      half_segment_length >>= 1;
    }
    for (int inner_depth = depth + 1; inner_depth <= max_depth - 11; ++inner_depth) {
      BitonicCompareKernel<VAL_T, ASCENDING, false><<<num_blocks, BITONIC_SORT_NUM_ELEMENTS>>>(values, half_segment_length, segment_length, static_cast<int>(len));
      SynchronizeCUDADeviceOuter(__FILE__, __LINE__);
      half_segment_length >>= 1;
    }
    BitonicSortMergeKernel<VAL_T, ASCENDING><<<num_blocks, BITONIC_SORT_NUM_ELEMENTS>>>(values, segment_length, static_cast<int>(len));
    SynchronizeCUDADeviceOuter(__FILE__, __LINE__);
  }
}